![image](https://github.com/MightEnlightenYou/LocalDev/assets/86793055/af808a01-fca9-4e69-adab-cf6c24a527e3)



LocalDev is in very early development stages.

Basically it intends to be the Devin, Devika, Pythagora, Mentat of local models. Built for local models only since the architecture will have to differ from how all other projects are doing it.

The intention is to have a capable LLM ran directly in code (probably using exl2 for speed) instead of using local servers through LM Studio, ooba and ollama and so on. This because all of the readily avaliable tools lack functions for models like function calling and the code to run a LLM isn't that advanced. Then it's mostly prompting and give ability to write files.

After the MVP is done the next step is internet search. After that probably RAG and function calling.

Will also add vision models, image generation, TTS/STT


Check the roadmap or issues to get more info.

All help with anything is greatly appreciated. 
